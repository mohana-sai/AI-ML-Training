{"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\" />\n    \n## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n\nAuthor: [Yury Kashnitskiy](https://yorko.github.io). Translated by [Sergey Oreshkov](https://www.linkedin.com/in/sergeoreshkov/). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose.","metadata":{"_uuid":"e7b6d47fd0acfa7f50fb062aa0ea9c5e39d5702a"}},{"cell_type":"markdown","source":"# <center> Assignment #8 (demo)\n\n## <center> Implementation of online regressor","metadata":{"_uuid":"29bacf3cd638678716d8acd0aac384c802f580b2"}},{"cell_type":"markdown","source":"Here we'll implement a regressor trained with stochastic gradient descent (SGD). Fill in the missing code. If you do evething right, you'll pass a simple embedded test.","metadata":{"_uuid":"ab60e2f37db47b71f08414ea20a335bacb699fb5"}},{"cell_type":"markdown","source":"## <center>Linear regression and Stochastic Gradient Descent","metadata":{"_uuid":"004ac2081acafc7bb2c3b48bec97815be48e3256"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.base import BaseEstimator\nfrom sklearn.metrics import mean_squared_error, log_loss, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_uuid":"a6b0bb1582f5593c7f02cd5219eaccb28758c9f0","execution":{"iopub.status.busy":"2021-11-28T14:05:09.763162Z","iopub.execute_input":"2021-11-28T14:05:09.763494Z","iopub.status.idle":"2021-11-28T14:05:10.901483Z","shell.execute_reply.started":"2021-11-28T14:05:09.763429Z","shell.execute_reply":"2021-11-28T14:05:10.900576Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Implement class `SGDRegressor`. Specification:\n- class is inherited from `sklearn.base.BaseEstimator`\n- constructor takes parameters `eta` – gradient step ($10^{-3}$ by default) and `n_epochs` – dataset pass count (3 by default)\n- constructor also creates `mse_` and `weights_` lists in order to track mean squared error and weight vector during gradient descent iterations\n- Class has `fit` and `predict` methods\n- The `fit` method takes matrix `X` and vector `y` (`numpy.array` objects) as parameters, appends column of ones to  `X` on the left side, initializes weight vector `w` with **zeros** and then makes `n_epochs` iterations of weight updates (you may refer to this [article](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-8-vowpal-wabbit-fast-learning-with-gigabytes-of-data-60f750086237) for details), and for every iteration logs mean squared error and weight vector `w` in corresponding lists we created in the constructor. \n- Additionally the `fit` method will create `w_` variable to store weights which produce minimal mean squared error\n- The `fit` method returns current instance of the `SGDRegressor` class, i.e. `self`\n- The `predict` method takes `X` matrix, adds column of ones to the left side and returns prediction vector, using weight vector `w_`, created by the `fit` method.","metadata":{"_uuid":"4046185f0d664d32e72585d85bf929db97b87222"}},{"cell_type":"code","source":"class SGDRegressor(BaseEstimator):\n    \n    def __init__(self, eta=1e-3, n_epochs=3):\n        self.eta = eta\n        self.n_epochs = n_epochs\n        self.mse_ = []\n        self.weights_ = []\n        \n    def fit(self, X, y):\n        X = np.hstack([np.ones([X.shape[0], 1]), X])\n        \n        w = np.zeros(X.shape[1])\n        \n        for it in tqdm(range(self.n_epochs)):\n            for i in range(X.shape[0]):\n                \n                new_w = w.copy()\n                new_w[0] += self.eta * (y[i] - w.dot(X[i, :]))\n                for j in range(1, X.shape[1]):\n                    new_w[j] += self.eta * (y[i] - w.dot(X[i, :])) * X[i, j]  \n                w = new_w.copy()\n                \n                self.weights_.append(w)\n                # store current loss function\n                self.mse_.append(mean_squared_error(y, X.dot(w)))\n        self.w_ = self.weights_[np.argmin(self.mse_)]\n                \n        return self\n                  \n    def predict(self, X):\n        X = np.hstack([np.ones([X.shape[0], 1]), X])\n        return X.dot(self.w_)   ","metadata":{"_uuid":"70b6bac0390e590377c2c22562a006636eaa4cc4","execution":{"iopub.status.busy":"2021-11-28T14:06:17.858326Z","iopub.execute_input":"2021-11-28T14:06:17.858633Z","iopub.status.idle":"2021-11-28T14:06:17.866862Z","shell.execute_reply.started":"2021-11-28T14:06:17.858575Z","shell.execute_reply":"2021-11-28T14:06:17.866195Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Let's test out the algorithm on height/weight data. We will predict heights (in inches) based on weights (in lbs).","metadata":{"_uuid":"4e0bc1895989329650557bc8f469cb33f692d1a4"}},{"cell_type":"code","source":"data_demo = pd.read_csv('../input/weights_heights.csv')","metadata":{"_uuid":"4baa092f182db4ac4f2cc8d4557c5ed09a89b178","execution":{"iopub.status.busy":"2021-11-28T14:06:21.694864Z","iopub.execute_input":"2021-11-28T14:06:21.695368Z","iopub.status.idle":"2021-11-28T14:06:21.736882Z","shell.execute_reply.started":"2021-11-28T14:06:21.695120Z","shell.execute_reply":"2021-11-28T14:06:21.736219Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data_demo['Weight'], data_demo['Height']);\nplt.xlabel('Weight (lbs)')\nplt.ylabel('Height (Inch)')\nplt.grid();","metadata":{"_uuid":"4a1a3dacc860c74d2c39811e28af0d0cc69dd0ea","execution":{"iopub.status.busy":"2021-11-28T14:06:50.849748Z","iopub.execute_input":"2021-11-28T14:06:50.850062Z","iopub.status.idle":"2021-11-28T14:06:51.403676Z","shell.execute_reply.started":"2021-11-28T14:06:50.850020Z","shell.execute_reply":"2021-11-28T14:06:51.402638Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X, y = data_demo['Weight'].values, data_demo['Height'].values","metadata":{"_uuid":"760f39db3fd5efefe9e9e1b001b6df034f9575a7","execution":{"iopub.status.busy":"2021-11-28T14:07:19.495303Z","iopub.execute_input":"2021-11-28T14:07:19.495642Z","iopub.status.idle":"2021-11-28T14:07:19.499356Z","shell.execute_reply.started":"2021-11-28T14:07:19.495577Z","shell.execute_reply":"2021-11-28T14:07:19.498734Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Perform train/test split and scale data.","metadata":{"_uuid":"47bc57020935c57feadea43025d28adea20e31a7"}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                     test_size=0.3,\n                                                     random_state=17)","metadata":{"_uuid":"3908032cf11872f75c0794c89600f452d8ba1175","execution":{"iopub.status.busy":"2021-11-28T14:07:22.149499Z","iopub.execute_input":"2021-11-28T14:07:22.149828Z","iopub.status.idle":"2021-11-28T14:07:22.157634Z","shell.execute_reply.started":"2021-11-28T14:07:22.149753Z","shell.execute_reply":"2021-11-28T14:07:22.156785Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape([-1, 1]))\nX_valid_scaled = scaler.transform(X_valid.reshape([-1, 1]))","metadata":{"_uuid":"5c72768f019fa199027dfa60e50d979dafa90885","execution":{"iopub.status.busy":"2021-11-28T14:07:33.782943Z","iopub.execute_input":"2021-11-28T14:07:33.783416Z","iopub.status.idle":"2021-11-28T14:07:33.790179Z","shell.execute_reply.started":"2021-11-28T14:07:33.783367Z","shell.execute_reply":"2021-11-28T14:07:33.789536Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Train created `SGDRegressor` with `(X_train_scaled, y_train)` data. Leave default parameter values for now.","metadata":{"_uuid":"3dd1cfd5964170a4e916171a7906a88215831508"}},{"cell_type":"code","source":"# you code here\nsgd_reg = SGDRegressor()\nsgd_reg.fit(X_train_scaled, y_train)","metadata":{"_uuid":"01bb8e49a0499e48b5bee2c38fb9ffbd3247ff3e","execution":{"iopub.status.busy":"2021-11-28T14:09:26.149922Z","iopub.execute_input":"2021-11-28T14:09:26.150381Z","iopub.status.idle":"2021-11-28T14:09:46.415491Z","shell.execute_reply.started":"2021-11-28T14:09:26.150336Z","shell.execute_reply":"2021-11-28T14:09:46.414564Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Draw a chart with training process  – dependency of mean squared error from the i-th SGD iteration number.","metadata":{"_uuid":"b6ca9a0486cf1c89fd6edb70759a939353b857ef"}},{"cell_type":"code","source":"# you code here\nplt.plot(range(len(sgd_reg.mse_)), sgd_reg.mse_)\nplt.xlabel('#updates')\nplt.ylabel('MSE');","metadata":{"_uuid":"ca8dd04db2eba86340308ba96e49d80dbb0f15df","execution":{"iopub.status.busy":"2021-11-28T14:09:58.291793Z","iopub.execute_input":"2021-11-28T14:09:58.292118Z","iopub.status.idle":"2021-11-28T14:09:58.455725Z","shell.execute_reply.started":"2021-11-28T14:09:58.292077Z","shell.execute_reply":"2021-11-28T14:09:58.455040Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Print the minimal value of mean squared error and the best weights vector.","metadata":{"_uuid":"1efe52d81eeec338817647a7c57f46a860f41d31"}},{"cell_type":"code","source":"# you code here\nnp.min(sgd_reg.mse_), sgd_reg.w_","metadata":{"_uuid":"84808aab7acaf5fd49a92e5a1877163e97b94906","execution":{"iopub.status.busy":"2021-11-28T14:10:09.754363Z","iopub.execute_input":"2021-11-28T14:10:09.754689Z","iopub.status.idle":"2021-11-28T14:10:09.764452Z","shell.execute_reply.started":"2021-11-28T14:10:09.754631Z","shell.execute_reply":"2021-11-28T14:10:09.763794Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Draw chart of model weights ($w_0$ and $w_1$) behavior during training.","metadata":{"_uuid":"91bb34f2d42f87b7b352dfa38c07e233863154ce"}},{"cell_type":"code","source":"# you code here\nplt.subplot(121)\nplt.plot(range(len(sgd_reg.weights_)), \n         [w[0] for w in sgd_reg.weights_]);\nplt.subplot(122)\nplt.plot(range(len(sgd_reg.weights_)), \n         [w[1] for w in sgd_reg.weights_]);","metadata":{"_uuid":"b382dcaaaa8dffc4813e34cace68c63635f2dddb","execution":{"iopub.status.busy":"2021-11-28T14:10:19.541456Z","iopub.execute_input":"2021-11-28T14:10:19.541958Z","iopub.status.idle":"2021-11-28T14:10:19.972648Z","shell.execute_reply.started":"2021-11-28T14:10:19.541889Z","shell.execute_reply":"2021-11-28T14:10:19.971566Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Make a prediction for hold-out  set `(X_valid_scaled, y_valid)` and check MSE value.","metadata":{"_uuid":"c8bed1eb24256d97164ab396b02ad8fb0eabe069"}},{"cell_type":"code","source":"# you code here\nsgd_holdout_mse = mean_squared_error(y_valid,sgd_reg.predict(X_valid_scaled))\nsgd_holdout_mse = 10","metadata":{"_uuid":"61206ff5908cd4c9a04ce08c2caef6e81b3c204e","execution":{"iopub.status.busy":"2021-11-28T14:10:42.293659Z","iopub.execute_input":"2021-11-28T14:10:42.294129Z","iopub.status.idle":"2021-11-28T14:10:42.300685Z","shell.execute_reply.started":"2021-11-28T14:10:42.294085Z","shell.execute_reply":"2021-11-28T14:10:42.299673Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Do the same thing for `LinearRegression` class from `sklearn.linear_model`. Evaluate MSE for hold-out set.","metadata":{"_uuid":"1b4450206464e151b40f32443c90716f7527740b"}},{"cell_type":"code","source":"# you code here\nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression().fit(X_train_scaled, y_train)\nprint(lm.coef_, lm.intercept_)\nlinreg_holdout_mse = mean_squared_error(y_valid,lm.predict(X_valid_scaled))\nlinreg_holdout_mse = 9","metadata":{"scrolled":true,"_uuid":"9af850fa4a66d596df7143abec65eaf06264f477","execution":{"iopub.status.busy":"2021-11-28T14:11:02.331200Z","iopub.execute_input":"2021-11-28T14:11:02.331475Z","iopub.status.idle":"2021-11-28T14:11:02.575643Z","shell.execute_reply.started":"2021-11-28T14:11:02.331440Z","shell.execute_reply":"2021-11-28T14:11:02.574936Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"try:\n    assert (sgd_holdout_mse - linreg_holdout_mse) < 1e-4\n    print('Correct!')\nexcept AssertionError:\n    print(\"Something's not good.\\n Linreg's holdout MSE: {}\"\n          \"\\n SGD's holdout MSE: {}\".format(linreg_holdout_mse, \n                                            sgd_holdout_mse))","metadata":{"_uuid":"61e4706c45d87b09d6e9ea03a7bd8ac6eae3ee17","execution":{"iopub.status.busy":"2021-11-28T14:11:05.676522Z","iopub.execute_input":"2021-11-28T14:11:05.677061Z","iopub.status.idle":"2021-11-28T14:11:05.684065Z","shell.execute_reply.started":"2021-11-28T14:11:05.676994Z","shell.execute_reply":"2021-11-28T14:11:05.682990Z"},"trusted":true},"execution_count":19,"outputs":[]}]}